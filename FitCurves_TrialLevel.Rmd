---
title: "Fit Curves"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---

# Merge datasets for all waves

# in wave 2, sessions 6 and 12 the button boxes was different for the controls
CHeck diffs wave 2 and rest, controls experimental in wave 2

```{r, warning = F}
#rm(ls = list())
library(rstan)
library(chron)
library(dplyr)
library(ggplot2)

options(mc.cores = parallel::detectCores())

theme_lh = function () { 
    theme_bw(base_size=20, base_family="Avenir")
}

u = function(x, x0){
  # step function
  y = x*0
  y[x > x0] = 1
  return(y)
}

estimate_learning = function(r0, e0, p0, kr, ke, kp, ti){ 
 N = length(ti)
 x = seq(0, N)
 p1 = sapply(seq(N), function(i) ((1 - kr)^(i-1))* u(x, ti[i]))
 q1 = rowSums(p1)

 p2 = sapply(seq(N), function(i) ((1 - kr)^(i-1))*exp(-kc*(x-ti[i]))* u(x, ti[i]))
 q2 = rowSums(p2)

 p3 = sapply(seq(N), function(i) ((1 - kr)^(i-1))*(1 - exp(-kc*(x-ti[i]))) * u(x, ti[i]))
 q3 = rowSums(p3)

 rt = r0*(1 - kr * q1)  
 cet = r0*kr*q2 + e0*exp(-kc*x)
 cpt = r0*kr*kp*q3/kc + kp*e0*(1 -  exp(-kc*x))/kc + p0
 ct = cet + cpt
 
 learning = (ct[length(ct)] - ct[1]) 
  
return(learning = learning, ct = ct)

}


WD = "~/Software/LeftHand/fitcurves"
DATADIR = file.path(WD, "./data/")
setwd(WD)
MINTRIALS = 10

markoutliers = function(x) { ifelse(abs(x - mean(x)) > 3*sd(x), NA, x) }

trials.table = read.table("./data/complete_trials_table.csv", header = T, sep = ";")

unpaced_trials = subset(trials.table, paced == 0 & trial_type != "missed")
paced_trials = subset(trials.table, paced == 1 & trial_type != "missed")

# signal trials that follow an error, do not consider missing data
cumulative_diff = c(0, diff(unpaced_trials$cumulative_trial))
true_sequence_diff = c(0, diff(as.numeric(unpaced_trials$true_sequence)))
username_diff = c(0, diff(as.numeric(unpaced_trials$username)))

posterror = c(0, unpaced_trials$accuracy[-nrow(unpaced_trials)] < 1)
unpaced_trials$posterror = (true_sequence_diff == 0 & username_diff == 0 & cumulative_diff == 1 & posterror)*1

# circadian patterns
unpaced_trials = unpaced_trials %>% mutate(sess_time_sin = sin(2*pi*as.numeric(times(sess_time))),
sess_time_cos = cos(2*pi*as.numeric(times(sess_time))))

# calculate training in days
unpaced_trials$sess_day=0
unpaced_trials$cum_day=0
unpaced_trials$sess_day_diff=0

mysubjects = unique(unpaced_trials$username)
for (name in mysubjects){
 unpaced_trials$sess_day[unpaced_trials$username == name] = round(difftime(unpaced_trials$sess_date[unpaced_trials$username == name], unpaced_trials$sess_date[unpaced_trials$username == name][1], units = "days"))
 mydays = unique(unpaced_trials$sess_day[unpaced_trials$username == name])
 mydiff = c(0, diff(mydays))
 cum_day = seq(length(unique(mydays)))
 names(mydiff) = names(cum_day) = mydays
 unpaced_trials$cum_day[unpaced_trials$username == name] = cum_day[as.character(unpaced_trials$sess_day[unpaced_trials$username == name])]
 unpaced_trials$sess_day_diff[unpaced_trials$username == name] = mydiff[as.character(unpaced_trials$sess_day[unpaced_trials$username == name])]
}

#View(unpaced_trials[c("username", "true_sequence", "cumulative_trial", "accuracy","posterror")])

ok_unpaced_trials = subset(unpaced_trials, accuracy == 1)
ok_unpaced_trials.clean = ok_unpaced_trials %>% group_by(username, sess_num, true_sequence) %>% mutate(MT = markoutliers(MT))
ok_paced_trials = subset(paced_trials, accuracy == 1)

subject_data = read.csv("~/Software/LeftHand/fitcurves/data/SubjectData.csv")

# prepare data
# lue1201 did the wrong first sessions an messes up the estimates
# select data
mytrials = subset(ok_unpaced_trials.clean, username != "lue1201" & seq_train == "trained" ) %>% filter(!is.na(MT)) 
mytrials = mytrials %>% arrange(username, sess_day, true_sequence, trial)%>%filter(trial > MINTRIALS)

mytrials$username = factor(mytrials$username)
mytrials$true_sequence = factor(mytrials$true_sequence)

```

# Plot data
```{r}
plot.MT = ggplot(mytrials, aes(x = sess_day, y = MT, group = username, col = trial)) + geom_line(size = 1) + geom_point(size = 2) + theme_lh() + xlab('Session') + ylab('Movement duration (ms)')  #+ facet_grid(username ~ . )
#print(plot.MT)

plot.MT = ggplot(mytrials, aes(x = trial, y = MT, group = sess_num, col = sess_num)) + geom_point(size = 0.1) + geom_line() + theme_lh() + xlab('Trial') + ylab('Movement duration (ms)')  + facet_grid(true_sequence ~username )
#print(plot.MT)

```

# Prepare session variables

```{r fig.width=25, fig.asp=0.4, warning= F}

# show that it is better than the 1 compartment model
# understand parameters
# check what happens with sess_day float?
# identify which parameters vary meaningfully
# study pairs plot
# different noise for different people
# get principal factor
# unfold trials and put wrong trials
# predict unseen session, preditct untrained
# errors are normal?

mytrials$cluster = as.numeric(as.factor(paste(mytrials$username, format(mytrials$sess_day, width = 2, flag = "0"), mytrials$true_sequence) ))
mysubjects = levels(mytrials$username)
myclusters = unique(mytrials[c("username", "sess_day", "cum_day", "true_sequence")])
mysessions = unique(mytrials[c("username", "sess_day", "cum_day")])

#View(myclusters) 

#Prepare covariates

mycovars = c("posterror", "physical_activity", "sleep", "cigarettes",  "liquid", "coffee", "alcohol")
mycovarsf = c("sess_time_cos", "sess_time_sin")
time_mat = matrix(0, length(mysubjects), max(myclusters$cum_day))

# how many sifferent sequences per subject?
Ndiffseqvec = NULL
for (s in mysubjects){
  aux = subset(myclusters, username == s)
  Ndiffseqvec[s] = length(unique(aux$true_sequence))
}
Ndiffseq = max(Ndiffseqvec) #only trained

Nseq = max(as.integer(mytrials$true_sequence))
seq_mat = matrix(0, length(mysubjects), Ndiffseq)

for (i in 1:length(mysubjects)){
  s = levels(mysessions$username)[i]
  for (j in mysessions$cum_day[mysessions$username == s]){
        time_mat[i, j] = mysessions$sess_day[mysessions$username == s][j]
  }
  seq_mat[i, ] = unique(myclusters$true_sequence[myclusters$username == s])

  }

# seq_mat  and time_mat in the same order as mysubjects!

stan_data = list(cluster = mytrials$cluster, 
                 trial = mytrials$trial, 
                 y = mytrials$MT, 
                 Nclus = max(mytrials$cluster), 
                 Nsub = length(mysubjects),
                 Nseq = Nseq,
                 Ndiffseq = Ndiffseq,
                 subject = as.integer(myclusters$username),
                 day = as.integer(myclusters$sess_day), 
                 cum_day = as.integer(myclusters$cum_day), 
                 max_cum_day = max(as.integer(myclusters$cum_day)), 
                 time_mat = time_mat, 
                 seq_mat = seq_mat,
                 sequence = as.integer(mytrials$true_sequence), 
                 N = nrow(mytrials), 
                 z = mytrials[mycovars],
                 zf = mytrials[mycovarsf],
                 Ncovars = length(mycovars),
                 Ncovarsf = length(mycovarsf)
                 )
# save data
save(stan_data, file = file.path(WD, "./data/stan_data.RData"))
stophere
```
#Three -compartment model

There is a post-error slowing effect ~ 100 ms
There is an effect of time of the day ~ 60 ms
Retention factor  .2 -.9

```{r fig.width=25, fig.asp=0.4, warning= F}
#stan_control = list(adapt_delta = 0.85, max_treedepth = 13)
stan_control = list(adapt_delta = 0.9, max_treedepth = 13)
ITER = 2000
WARMUP = 1500

stan_init.1 = function() {list(mu_hyp_csub = c(-1, -2.5, -2, rep(0, 3)),
                             sigma_hyp_csub = c(1, 0.1, 1, rep(0.2, 3)),
                             sigma = 250,
                             mu_hyp_seq = rep(0, 6),
                             sigma_hyp_seq = rep(100, 6),
                             mu_hyp_beta = rep(0, 7),
                             sigma_hyp_beta = rep(50, 7))}
stan_init.0 = function() {list(mu_hyp_csub = c(-1, 0),
                             sigma_hyp_csub = c(1, 0.2),
                             sigma = 250,
                             mu_hyp_seq = rep(0, 6),
                             sigma_hyp_seq = rep(100, 6),
                             mu_hyp_beta = rep(0, 7),
                             sigma_hyp_beta = rep(50, 7))}
if (T){   
fit.1 = stan(file = "learning_model_constant3comp_HR.stan", chains = 4, iter = ITER, warmup = WARMUP, data = stan_data, control = stan_control, init = stan_init.1)
fit.0 = stan(file = "learning_model_constant1comp_HR.stan", chains = 4, iter = ITER, warmup = WARMUP, data = stan_data, control = stan_control)

# save results
saveRDS(fit.1, fit.0, file = file.path(WD, "./results/", paste0("fit-", format(Sys.time(), "%d%m%y_%H%M"), ".rds")))

} else {
myfit = readRDS("~/Software/LeftHand/fitcurves/results/fit-260221_1908.rds")
}

# compare models
#loo.1 = loo(fit.1)
#loo.0 = loo(fit.0)
```


```{r fig.width=25, fig.asp=0.4, warning= F}
# check chains

myfit = myfit
traceplot(myfit, par = c('mu_hyp_csub', 'sigma_hyp_csub','sigma', 'mu_hyp_beta', 'sigma_hyp_beta', 'mu_hyp_seq', 'sigma_hyp_seq'), inc_warmup = T)
traceplot(myfit, par = c( 'mu_hyp_csub', 'sigma_hyp_csub', 'sigma'))
plot(myfit, par = c('mu_hyp_csub', 'sigma_hyp_csub'))
plot(myfit, par = c('mu_hyp_seq',  'sigma_hyp_seq'))
pairs(myfit, pars = c( 'mu_hyp_csub[1]', 'mu_hyp_csub[3]', 
                       'sigma_hyp_csub[1]', 'sigma_hyp_csub[3]'))

plot(myfit, par = 'mu_hyp_beta')
plot(myfit, par = c('r0_c_mean', 'e0_c_mean', 'p0_c_mean', 'kr_c_mean', 'ke_c_mean', 'kp_c_mean'))
plot(myfit, par = 'retention_c')
#check parameters

plot(myfit, par = paste0('csub[', seq(stan_data$Nsub), ',1]'), main = "r0")
plot(myfit, par = paste0('csub[', seq(stan_data$Nsub), ',2]'), main = "e0")
plot(myfit, par = paste0('csub[', seq(stan_data$Nsub), ',3]'), main = "c0")
plot(myfit, par = paste0('csub[', seq(stan_data$Nsub), ',4]'), main = "kr")
plot(myfit, par = paste0('csub[', seq(stan_data$Nsub), ',5]'), main = "ke")
plot(myfit, par = paste0('csub[', seq(stan_data$Nsub), ',6]'), main = "kc")

params = summary(myfit)$summary[, "mean"]
rhat = summary(myfit)$summary[, "Rhat"]
neff = summary(myfit)$summary[, "n_eff"]

r0_c = params[grep("\\br0_c\\[", names(params))]
e0_c = params[grep("\\be0_c\\[", names(params))]
p0_c = params[grep("\\bp0_c\\[", names(params))]
kr_c = params[grep("\\bkr_c\\[", names(params))]
ke_c = params[grep("\\bke_c\\[", names(params))]
kp_c = params[grep("\\bkp_c\\[", names(params))]

r0_c_mean = params[grep("r0_c_mean", names(params))]
e0_c_mean = params[grep("e0_c_mean", names(params))]
p0_c_mean = params[grep("p0_c_mean", names(params))]
kr_c_mean = params[grep("kr_c_mean", names(params))]
ke_c_mean = params[grep("ke_c_mean", names(params))]
kp_c_mean = params[grep("kp_c_mean", names(params))]

csub = matrix(params[grep("\\bcsub\\[", names(params))], , 6, byrow = T)

subparams = csub
colnames(subparams) = c("csub1", "csub2", "csub3", "csub4", "csub5", "csub6")
rownames(subparams) = seq(nrow(subparams))
parcor = cor(subparams)
beta_all = params[grep("\\bbeta\\[", names(params))]
beta = matrix(beta_all, , stan_data$Ncovars)
colnames(beta) = mycovars
#beta.samples = rstan::extract(myfit, par = "beta")$beta
betaf_all = params[grep("betaf\\[", names(params))]
betaf = matrix(betaf_all, , stan_data$Ncovarsf)
colnames(betaf) = mycovarsf
betaf.samples = rstan::extract(myfit, par = "betaf")$betaf

plot(betaf[,1], betaf[,2], pch = 20)
time_effect = apply(betaf.samples, c(1, 3), function(x) sqrt(sum(x^2)))

y_new = params[grep("y_new\\[", names(params))]

results = mytrials[c("username", "group", "sess_day", "trial", "MT", "true_sequence")] %>% group_by(username, true_sequence) %>% mutate(ind = row_number())
results$MT.pred = y_new

plot(results$MT, results$MT.pred, pch = 20, xlab = "Measured MT (ms)", ylab = "Predicted MT (ms)", cex = 0.1)
abline(0, 1)

# explained variance
exp.var = 1 - var(results$MT - results$MT.pred)/var(results$MT)

myplot = ggplot(results, aes(x = trial, y = MT, col = true_sequence)) + geom_point(size = 0.2) + geom_line(aes(x = trial, y = MT.pred, group = true_sequence, col = true_sequence), size = 0.9) + theme_classic() + facet_grid(username ~ sess_day)
print(myplot)

myplot = ggplot(results, aes(x = ind, y = MT, col = as.factor(sess_day))) + geom_point(size = 0.2) + geom_line(aes(x = ind, y = MT.pred, group = as.factor(sess_day)), col = "black" ) + theme_classic() + facet_grid(username ~ true_sequence)
print(myplot)

results.mean = results %>% group_by(username, group, sess_day, trial) %>% summarise(MT.pred = mean(MT.pred), MT = mean(MT))
myplot = ggplot(results.mean, aes(x = trial, y = MT, col = username)) + geom_line(size = 0.2) + geom_line(aes(x = trial, y = MT.pred, group = username, col = username), size = 0.7) + theme_classic() + facet_grid(group ~ sess_day)
print(myplot)

#myplot = ggplot(results, aes(x = trial, y = MT, col = true_sequence)) + geom_point() + geom_line(aes(x = trial, y = MT.pred, group = true_sequence, col = true_sequence)) + theme_classic() + facet_grid(sess_day ~ username )
#print(myplot)

# sequence difficulty differences
# which parameters vary meaningfully by comparing parameter uncertainty with variability across subjects
csub.samp = rstan::extract(myfit, par = "csub")$csub

csub.wt = colMeans(apply(csub.samp, c(2, 3), sd))
csub.bt = apply(apply(csub.samp, c(2, 3), mean), 2, sd)
var.ratio = csub.bt/csub.wt
print (var.ratio)
# sequence differences



library(shinystan)
launch_shinystan(myfit)
stophere

```

#Characterize results
```{r}
library(psych)
library(nFactors)
library(factoextra)
mypars = as.data.frame(scale(subparams))
colnames(mypars) = c("r0", "e0", "c0", "kr", "ke", "kc")
pca = principal(mypars, nfactors = 2, residuals = F, rotate = "varimax")
#pca = principal(mypars, nfactors = 6, residuals = F, rotate = "none")
eigenvalues = pca$values
nsubjects = pca$n.obs
variables = length(eigenvalues)
rep = 2000
cent = 0.95
aparallel = parallel(var = variables,
                     subject = nsubjects, 
                     rep = rep,
                     cent = cent)$eigen$qevpea
results.scree = nScree (x = eigenvalues, aparallel = aparallel)
summary(results.scree)
plotnScree(results.scree)
plot(pca)
```

# Check how much they learned
```{r}
learning = NULL
for (j in seq(stan_data$Nsub )){ 
  ti = stan_data$time_mat[j, ]  
  ti = ti[ti <= max(ti)] 
  learning[j] = estimate_learning(r0_c[j] , e0_c[j], p0_c[j], kr_c[j], ke_c[j], kp_c[j], ti)
}
```

# Are there differences between groups?
```{r}
mygroup = rep("Intervention", length(mysubjects))
mygroup[grep("lue(.)2", mysubjects)] = "Control"
# is there a diff in parameters between groups?
pvalues = apply(mypars, 2, function (x){  boxplot(x ~ mygroup); t.test(x ~ mygroup )$p.value})

parcor = cor(mypars)
pairs(mypars)
#pca = princomp(mypars, cor = T)
plot(pca)
plot(cumsum(pca$values*2)/sum(pca$value*2)*100)
print(pca$loadings)

pairs(mypars)
components = as.data.frame(pca$scores)
components$StudyID = mysubjects
components = merge(components, subject_data, by = "StudyID")
components = cbind(components, mypars)
components$group = mygroup
cor(components[c("RC1", "RC2", "reasoning")] )
#cor(components[c("Comp.1", "Comp.2", "Comp.3", "Comp.4", "Comp.5", "Comp.6", "reasoning")] )
parcor = cor(cbind(mypars, components[c("Comp.1", "Comp.2", "Comp.3", "Comp.4", "Comp.5", "Comp.6", "reasoning")] )[mygroup == "Intervention", ])
var = 'kr'
mymodel = lm(as.formula(paste(var,  'group*gender', sep = '~')),  data = components)
summary(mymodel)

image(parcor)
plot(components$reasoning, components$Comp.2)
print(components %>% arrange(desc(Comp.2)))

print(head(mypars %>% arrange(desc(improve))) )

mypars$username = mysubjects
K = merge(sess.diff, mypars, by = "username")
cor.test(K$meanMT.diff, K$improve)
plot(K$meanMT.diff, K$improve)
text(K$meanMT.diff, K$improve, labels = as.character(K$username))

```









```{r}

# actual date since start
# time of the day
#difference in hours
# check how you get the first day

ok_trials = subset(trials.table, accuracy == 1 &  paced == 0 & trial_type != 'missed' ) %>% mutate(sess_time_sin = sin(2*pi*as.numeric(times(sess_time))),
sess_time_cos = cos(2*pi*as.numeric(times(sess_time))))
ok_trials$sess_day=0
ok_trials$sess_day_diff=0

mysubjects = unique(ok_trials$username)

# calculate training in days
for (name in mysubjects){
ok_trials$sess_day[ok_trials$username == name] = difftime(ok_trials$sess_date[ok_trials$username == name], ok_trials$sess_date[ok_trials$username == name][1], units = "days")
mydays = unique(ok_trials$sess_day[ok_trials$username == name])
mydiff = c(0, diff(mydays))
names(mydiff) = mydays
ok_trials$sess_day_diff[ok_trials$username == name] = mydiff[as.character(ok_trials$sess_day[ok_trials$username == name])]
}
ok_trials = subset(ok_trials, group %in% 'Experimental')

## learning : add & username %in% learners &

#ok_trials_learning = subset(ok_trials, trial > 10 & seq_train == 'trained') %>% group_by(username, true_sequence, sess_num) %>% summarise(medianMT = median(MT), sdMT = sd(MT))
ok_trials_learning = subset(ok_trials, trial > 10 & seq_train == 'trained') %>% group_by(username, sess_num, sess_time, sess_time_sin, sess_time_cos, sess_day, sess_day_diff) %>% summarise(medianMT = median(MT), sdMT = sd(MT), medianRT = median(RT)/1000)
ok_trials_learning$username = droplevels(ok_trials_learning$username)

ok_trials_learning$cluster = as.numeric(as.factor(paste(ok_trials_learning$true_sequence, ok_trials_learning$username)))
ok_trials_learning$cluster = as.numeric(as.factor(ok_trials_learning$username))
mysubjects = levels(as.factor(ok_trials_learning$username))

mycovars = c("sess_time_sin", "sess_time_cos", "sess_day_diff", "medianRT")
# fit with stan
stan_data = list(cluster = ok_trials_learning$cluster, x = ok_trials_learning$sess_day, y = ok_trials_learning$medianMT, 
                 Nclus = max(ok_trials_learning$cluster), 
                 N = nrow(ok_trials_learning),
                 z = ok_trials_learning[mycovars],
                 Ncovars = length(mycovars))


stan_control = list(adapt_delta = 0.9, max_treedepth = 12)
ITER = 2000
WARMUP = 1500

stan_init = function() {list(mu_hyp = c(800, .3, 1300), sigma_hyp = c(500, .2, 300))}

#fit = stan(file = "exponential_fit.stan", chains = 4, iter = 5000, warmup = 400, data = stan_data,
myfit = stan(file = "learning_model_single1_HR.stan", chains = 4, iter = ITER, warmup = WARMUP, data = stan_data, control = stan_control, init = stan_init)

plot(myfit, par = c('a1'))
plot(myfit, par = c('b1'))
plot(myfit, par = c('c', 'sigma'))
plot(myfit, par = c('beta'))

params = summary(myfit)$summary[, "mean"]
a1 = params[grep("a1\\[", names(params))]
b1 = params[grep("b1\\[", names(params))]
c = params[grep("c\\[", names(params))]
beta_all = params[grep("beta\\[", names(params))]
beta = t(matrix(beta_all, , stan_data$Ncovars))
beta.samples = rstan::extract(myfit, par = "beta")$beta
y_new = params[grep("y_new\\[", names(params))]

beta.means = apply(beta.samples, c(1, 2), mean)
hist(beta.means[, 3], 100)

hist(beta.means[, 1], 100)
hist(beta.means[, 2], 100)

xx = seq(0, 1, 0.05)
yy = beta.means[, 1]%*%t(as.matrix(sin(2*pi*xx))) + beta.means[, 2]%*%t(as.matrix(cos(2*pi*xx)))
matplot(xx*24, t(yy), pch = 20, type = "b", cex = 0.3)

plot(stan_data$y, pch = 20, type = "l")
lines(y_new, col = "red")

#plot(stan_data$x, stan_data$y, pch = 20)
#lines(stan_data$x, y_new, col = "red")

for(j in unique(stan_data$cluster)){
  
  par(mfrow = c(1, 2))
  y = stan_data$y[stan_data$cluster == j]
  x = stan_data$x[stan_data$cluster == j]
  z = stan_data$z[stan_data$cluster == j, ]
  tt = as.numeric(times(ok_trials_learning$sess_time[stan_data$cluster == j]))*24
  
  plot(x, y, pch = 20, main = mysubjects[j], type = "l", cex = .5, ylim = c(0, 3500))
  lines(x, a1[j]*exp(-b1[j]*x) + c[j], col = "red")
  lines(x, a1[j]*exp(-b1[j]*x) + as.matrix(z) %*% beta[, j ] + c[j], col = "red", lwd = 2)
  plot(tt, unlist(beta[1, j]*z[, 1] + beta[2, j]*z[, 2]), ylab = "MT", xlab = "Hour", type = "p", ylim = c(-200, 200), xlim = c(0, 24)) 
}

traceplot(myfit, par = c('a1[1]', 'b1[1]', 'c[1]', 'sigma'))
traceplot(myfit, par = c('mu_hyp', 'sigma_hyp'))

mypars = as.data.frame(cbind(a1, b1, c, beta[3, ]))

colnames(mypars) = c("a", "b", "c", "consol")

cor(mypars)
pairs(mypars)
pca = princomp(mypars, cor = T)
plot(pca)
plot(cumsum(pca$sdev*2)/sum(pca$sdev*2)*100)
print(pca$loadings)
mypars = mypars %>% mutate(improve = (c + a) / (c + a*exp(-b*36)))

components = as.data.frame(pca$scores)
components$StudyID = mysubjects
components = merge(components, subject_data, by = "StudyID")


plot(components$reasoning, components$Comp.2)
print(components %>% arrange(desc(Comp.2)))

print(head(mypars %>% arrange(desc(improve))) )

mypars$username = mysubjects
K = merge(sess.diff, mypars, by = "username")
cor.test(K$meanMT.diff, K$improve)
plot(K$meanMT.diff, K$improve)
text(K$meanMT.diff, K$improve, labels = as.character(K$username))
```

Prediction
Seeing the beginning how well can I predict the end?

```{r}

```

Compare to IQ
```{r}

summary(lm(mypars$consol ~ gender, data = components)) # guys are faster

summary(lm(Comp.1 ~ gender, data = components))
summary(lm(Comp.2 ~ gender, data = components))

summary(lm(reasoning ~ gender, data = components))

boxplot(Comp.1 ~ gender, data = components)
boxplot(Comp.2 ~ gender, data = components)

cor.test(components$reasoning, components$Comp.1)
cor.test(components$reasoning, components$Comp.2)

# try with all subjects, correlation between c and reasoning
# reasoning correlates with max value but not initial?

```


```{r}
stophere

#pairs(fit, pars = c('mu_hyp', 'sigma_hyp'))
#traceplot(fit, par = c('mu_hyp', 'sigma_hyp'))
#pairs(fit, par = 'mu_hyp')
fit.2 = stan(file = "learning_model_single2.stan", chains = 4, iter = ITER, warmup = WARMUP, data = stan_data, control = stan_control)

traceplot(fit.2, par = c('a1', 'a2'))
plot(fit.2, par = c('a1', 'a2'))
plot(fit.2, par = c('b1', 'b2'))
pairs(fit.2, par = c('a1[1]', 'a1[2]', 'a2[1]', 'a2[1]'))
pairs(fit.2, par = c('b1[1]', 'b1[2]', 'b2[1]', 'b2[1]'))
pairs(fit.2, par = c('b1[1]', 'b1[2]'))
traceplot(fit.2, par = c('b1', 'b2'))

plot(fit.2, par = c('a1'))
plot(fit.2, par = c('b1'))
plot(fit.2, par = c('a2'))
plot(fit.2, par = c('b2'))
plot(fit.2, par = c('c'))

params = summary(fit)$summary[, "mean"]
a1 = params[grep("a1\\[", names(params))]
b1 = params[grep("b1\\[", names(params))]
a2 = params[grep("a2\\[", names(params))]
b2 = params[grep("b2\\[", names(params))]
c = params[grep("c\\[", names(params))]

y_new = params[grep("y_new\\[", names(params))]
trials.table.rate = ok_trials_learning %>% group_by(username, true_sequence, cluster) %>% summarise(rateRT = b1[cluster[1]])

# calculate likelihood and compare
# plot fits for 1 and 2 exponential models 
# for(j in unique(ok_trials_learning$cluster)){
#   mydata = subset(as.data.frame(ok_trials_learning), cluster == j)
#   y = mydata$medianRT
#   x = mydata$sess_num
#   plot(x, y, pch = 20, cex = 1, main = j)
#   lines(x, a1[j]*exp(-b1[j]*x) + a2[j]*exp(-b2[j]*x) + c[j], col = "red")
# }


plot(trials.table.rate$username, trials.table.rate$rateRT, las = 2)

# trials.table.rank= trials.table.rate %>% arrange(username, true_sequence, rateRT) %>% group_by(username) %>% mutate(rankRT = percent_rank(rateRT), true_sequence = as.character(true_sequence)) %>% mutate(true_sequence = as.factor(true_sequence), sequence_length  = nchar(as.character(true_sequence)), 
# n1 = str_count(true_sequence, "1"),
# n2 = str_count(true_sequence, "2"),
# n3 = str_count(true_sequence, "3"),
# n4 = str_count(true_sequence, "4"))
# 
# plot(jitter(trials.table.rank$sequence_length), jitter(trials.table.rank$rankRT))
# 
# trials.table.ranked = trials.table.rank %>% group_by(true_sequence, sequence_length) %>% summarise(medianrank = median(rankRT), count = n(), minrank = min(rankRT), maxrank = max(rankRT)) %>% arrange(medianrank) 
# 
# plot(trials.table.ranked$medianrank, lwd = 2, type = "l")
# lines(trials.table.ranked$minrank, lty = 2)
# lines(trials.table.ranked$maxrank, lty = 2)
# 
# plot(trials.table.ranked$sequence_length, trials.table.ranked$medianrank)
# 
# lm (rankRT ~ n1 + n2 + n3 + n4, data = trials.table.rank)
# summary(lm (rankRT ~ n1 + n2 + n3 + n4, data = trials.table.rank))

```


# Evaluate the best
```{r fig.width=25, fig.asp=0.7, warning = F}

last_trials = subset(ok_unpaced_trials.clean, group == "Experimental" & trial > MINTRIALS) %>% 
  group_by(username, sess_num, followup, wave) %>% 
  dplyr::summarise(meanMT = mean(MT, na.rm = T), sdMT = sd(MT, na.rm = T))

completers = names(which(table(last_trials$username)>=36))

# select ones with all sessions
sess.first = subset(last_trials, sess_num == 1)
sess.last = subset(last_trials, sess_num == 30)

sess.diff = merge(sess.first, sess.last, by = "username", suffix = c(".first", ".last")) %>% mutate(meanMT.diff = meanMT.first - meanMT.last, meanMT.diffrel = (meanMT.first - meanMT.last)/ meanMT.first) %>% arrange(desc(meanMT.diffrel))%>% mutate(order = row_number(sess_num.first))  %>% mutate( winner = order < 4)

head(sess.diff[c("order", "username", "meanMT.diff", "meanMT.diffrel")])
last_trials = merge(last_trials, sess.diff, by = "username", all.x = T) %>% filter (username %in% completers)

plot.meanMT = ggplot(last_trials, aes(x = sess_num, y = meanMT, group = username, col = !winner)) + geom_line(size = 2) + geom_point(size = 3) + theme_lh() + xlab('Session') + ylab('Movement duration (ms)') 
print(plot.meanMT)

```
